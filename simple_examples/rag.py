import time
from concurrent.futures import ThreadPoolExecutor, TimeoutError
from dotenv import load_dotenv
from sage.utils.custom_logger import CustomLogger
from sage.core.api.local_environment import LocalEnvironment
from sage.core.function.batch_function import BatchFunction
from sage.core.function.map_function import MapFunction
from sage.lib.io.sink import TerminalSink
from sage.lib.rag.promptor import QAPromptor
from sage.utils.config_loader import load_config

import os
import json
import requests
from typing import Any, List, Tuple


class OpenAIGenerator(MapFunction):
    """
    ç”ŸæˆèŠ‚ç‚¹ï¼šè°ƒç”¨ OpenAI-Compatible / VLLM / DashScope ç­‰ç«¯ç‚¹ã€‚
    """

    def __init__(self, config: dict, enable_profile=False, **kwargs):
        super().__init__(**kwargs)
        self.config = config
        self.enable_profile = enable_profile

        # Profileæ•°æ®å­˜å‚¨è·¯å¾„
        if self.enable_profile:
            if hasattr(self.ctx, 'env_base_dir') and self.ctx.env_base_dir:
                self.data_base_path = os.path.join(self.ctx.env_base_dir, ".sage_states", "generator_data")
            else:
                self.data_base_path = os.path.join(os.getcwd(), ".sage_states", "generator_data")
            os.makedirs(self.data_base_path, exist_ok=True)
            self.data_records = []

        self.num = 1
        self.session = requests.Session()

    def _call_openai_api(self, prompt: str) -> str:
        url = self.config["base_url"].rstrip("/") + "/chat/completions"
        headers = {
            "Content-Type": "application/json",
        }
        if self.config.get("api_key"):
            headers["Authorization"] = f"Bearer {self.config['api_key']}"

        # å¼ºåˆ¶ä¿è¯ prompt æ˜¯å­—ç¬¦ä¸²ï¼
        if not isinstance(prompt, str):
            prompt = str(prompt)

        payload = {
            "model": self.config["model_name"],
            "messages": [{"role": "user", "content": prompt}],
            "temperature": float(self.config.get("temperature", 0.7)),
            "max_tokens": int(self.config.get("max_tokens", 1024)),
        }

        resp = self.session.post(url, headers=headers, json=payload, timeout=60)
        if resp.status_code != 200:
            print(f"===> DashScopeè¿”å›: {resp.status_code} {resp.text}")
            resp.raise_for_status()
        data = resp.json()
        return data["choices"][0]["message"]["content"]

    def _save_data_record(self, query, prompt, response):
        if not self.enable_profile:
            return
        record = {
            'timestamp': time.time(),
            'query': query,
            'prompt': prompt,
            'response': response,
            'model_name': self.config["model_name"]
        }
        self.data_records.append(record)
        self._persist_data_records()

    def _persist_data_records(self):
        if not self.enable_profile or not self.data_records:
            return
        timestamp = int(time.time())
        filename = f"generator_data_{timestamp}.json"
        path = os.path.join(self.data_base_path, filename)
        try:
            with open(path, 'w', encoding='utf-8') as f:
                json.dump(self.data_records, f, ensure_ascii=False, indent=2)
            self.data_records = []
        except Exception as e:
            print(f"Failed to persist data records: {e}")

    def execute(self, data: List[Any]) -> Tuple[str, str]:
        user_query = data[0] if len(data) > 1 else None
        prompt = data[1] if len(data) > 1 else data[0]

        print("ğŸ¤– æ­£åœ¨ç”Ÿæˆå›ç­”...")
        try:
            response = self._call_openai_api(prompt)
            # æ¸…ç†é‡å¤çš„Answerå‰ç¼€
            if response.strip().startswith("Answer:"):
                response = response.strip()[7:].strip()
            print("âœ… å›ç­”ç”Ÿæˆå®Œæˆ")
        except Exception as e:
            response = f"[OpenAIGenerator ERROR] {e}"
            print(f"âŒ å›ç­”ç”Ÿæˆå¤±è´¥: {e}")

        self.num += 1

        if self.enable_profile:
            self._save_data_record(user_query, prompt, response)

        return user_query, response

    def __del__(self):
        if hasattr(self, 'enable_profile') and self.enable_profile:
            try:
                self._persist_data_records()
            except:
                pass


class PrivateKnowledgeBuilder:
    """ç§å¯†ä¿¡æ¯çŸ¥è¯†åº“æ„å»ºå™¨"""
    
    def __init__(self, collection_name="private_info_knowledge", index_name="private_index"):
        self.collection_name = collection_name
        self.index_name = index_name
        self.knowledge_sentences = [
            "å¼ å…ˆç”Ÿé€šå¸¸å°†æ‰‹æœºæ”¾åœ¨åŠå…¬æ¡Œå³ä¾§çš„æŠ½å±‰é‡Œï¼Œå……ç”µçº¿åœ¨å·¦ä¾§æŠ½å±‰ã€‚",
            "å¼ å…ˆç”Ÿçš„è½¦é’¥åŒ™ä¸€èˆ¬æ”¾åœ¨ç„å…³æŸœçš„å°ç›’å­é‡Œï¼Œå¤‡ç”¨é’¥åŒ™åœ¨å§å®¤æ¢³å¦†å°ã€‚",
            "å¼ å…ˆç”Ÿå–œæ¬¢åœ¨å‘¨äºŒå’Œå‘¨å››çš„ä¸‹åˆ3ç‚¹å»é™„è¿‘çš„å’–å•¡å…å·¥ä½œã€‚",
            "æå¥³å£«å–œæ¬¢æŠŠé’±åŒ…æ”¾åœ¨æ‰‹æåŒ…çš„å†…ä¾§æ‹‰é“¾è¢‹ä¸­ï¼Œä»ä¸æ”¾åœ¨å¤–å±‚ã€‚",
            "æå¥³å£«çš„æŠ¤ç…§å’Œé‡è¦è¯ä»¶æ”¾åœ¨å§å®¤è¡£æŸœé¡¶å±‚çš„è“è‰²æ–‡ä»¶å¤¹é‡Œã€‚",
            "æå¥³å£«çš„æ‰‹æœºé€šå¸¸æ”¾åœ¨å§å®¤åºŠå¤´æŸœä¸Šï¼Œä½†é’¥åŒ™æ”¾åœ¨å¨æˆ¿æŠ½å±‰é‡Œã€‚",
            "ç‹ç»ç†çš„åŠå…¬å®¤é’¥åŒ™é€šå¸¸æŒ‚åœ¨è…°é—´çš„é’¥åŒ™æ‰£ä¸Šï¼Œå¤‡ç”¨é’¥åŒ™åœ¨ç§˜ä¹¦é‚£é‡Œã€‚",
            "ç‹ç»ç†å¼€ä¼šæ—¶ä¹ æƒ¯å¸¦ç€é»‘è‰²çš„çš®è´¨è®°äº‹æœ¬ï¼Œé‡Œé¢è®°å½•ç€é‡è¦è”ç³»äººä¿¡æ¯ã€‚",
            "ç‹ç»ç†çš„æ‰‹æœºæ”¾åœ¨åŠå…¬æ¡Œä¸Šï¼Œä½†é‡è¦æ–‡ä»¶é”åœ¨ä¿é™©æŸœé‡Œã€‚",
            "å¼ å…ˆç”Ÿçš„é’±åŒ…æ”¾åœ¨è£¤å­å£è¢‹é‡Œï¼Œæå¥³å£«çš„è¯ä»¶åœ¨æŠ½å±‰ä¸­ã€‚"
        ]

    def ensure_knowledge_base_exists(self):
        """ç¡®ä¿çŸ¥è¯†åº“å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º"""
        try:
            from sage.service.memory.memory_service import MemoryService
            from sage.utils.embedding_methods.embedding_api import apply_embedding_model
            
            embedding_model = apply_embedding_model("default")
            dim = embedding_model.get_dim()
            memory_service = MemoryService()
            
            collections = memory_service.list_collections()
            if collections["status"] == "success":
                collection_names = [c["name"] for c in collections["collections"]]
                if self.collection_name in collection_names:
                    print(f"âœ… çŸ¥è¯†åº“ '{self.collection_name}' å·²å­˜åœ¨")
                    return True
            
            print(f"ğŸš€ åˆ›å»ºç§å¯†ä¿¡æ¯çŸ¥è¯†åº“ '{self.collection_name}'...")
            return self._create_knowledge_base(memory_service, embedding_model, dim)
            
        except Exception as e:
            print(f"âŒ æ£€æŸ¥/åˆ›å»ºçŸ¥è¯†åº“å¤±è´¥: {e}")
            return False

    def _create_knowledge_base(self, memory_service, embedding_model, dim):
        """åˆ›å»ºçŸ¥è¯†åº“"""
        collection_result = memory_service.create_collection(
            name=self.collection_name,
            backend_type="VDB",
            description="Private information RAG knowledge base",
            embedding_model=embedding_model,
            dim=dim
        )

        if collection_result["status"] != "success":
            print(f"âŒ åˆ›å»ºé›†åˆå¤±è´¥: {collection_result['message']}")
            return False

        print("ğŸ“š æ’å…¥çŸ¥è¯†å¥å­...")
        success_count = 0
        for i, sentence in enumerate(self.knowledge_sentences):
            result = memory_service.insert_data(
                collection_name=self.collection_name,
                text=sentence,
                metadata={"id": i + 1, "topic": "private_info", "type": "knowledge", "source": "manual"}
            )
            if result["status"] == "success":
                success_count += 1

        print(f"âœ… æˆåŠŸæ’å…¥ {success_count}/{len(self.knowledge_sentences)} å¥çŸ¥è¯†")

        index_result = memory_service.create_index(
            collection_name=self.collection_name,
            index_name=self.index_name,
            description="ç§å¯†ä¿¡æ¯æ£€ç´¢ç´¢å¼•"
        )

        if index_result["status"] != "success":
            print(f"âŒ ç´¢å¼•åˆ›å»ºå¤±è´¥: {index_result['message']}")
            return False

        print(f"âœ… å†…å­˜çŸ¥è¯†åº“æ„å»ºå®Œæˆ")
        return True


class PrivateQABatch(BatchFunction):
    """
    ç§å¯†ä¿¡æ¯QAæ‰¹å¤„ç†æ•°æ®æºï¼šå†…ç½®ç§å¯†é—®é¢˜åˆ—è¡¨
    """
    def __init__(self, config, **kwargs):
        super().__init__(**kwargs)
        self.counter = 0
        self.questions = [
            "å¼ å…ˆç”Ÿçš„æ‰‹æœºé€šå¸¸æ”¾åœ¨ä»€ä¹ˆåœ°æ–¹ï¼Ÿ",
            "æå¥³å£«å–œæ¬¢æŠŠé’±åŒ…æ”¾åœ¨å“ªé‡Œï¼Ÿ", 
            "ç‹ç»ç†çš„åŠå…¬å®¤é’¥åŒ™é€šå¸¸åœ¨å“ªé‡Œï¼Ÿ",
            "å¼ å…ˆç”Ÿä»€ä¹ˆæ—¶å€™ä¼šå»å’–å•¡å…å·¥ä½œï¼Ÿ",
            "æå¥³å£«çš„é‡è¦è¯ä»¶æ”¾åœ¨ä»€ä¹ˆåœ°æ–¹ï¼Ÿ",
            "ç‹ç»ç†å¼€ä¼šæ—¶é€šå¸¸ä¼šå¸¦ä»€ä¹ˆï¼Ÿ"
        ]

    def execute(self):
        """è¿”å›ä¸‹ä¸€ä¸ªé—®é¢˜ï¼Œå¦‚æœæ²¡æœ‰æ›´å¤šé—®é¢˜åˆ™è¿”å›None"""
        if self.counter >= len(self.questions):
            print("âœ… æ‰€æœ‰é—®é¢˜å¤„ç†å®Œæˆ")
            return None  # è¿”å›Noneè¡¨ç¤ºæ‰¹å¤„ç†å®Œæˆ

        question = self.questions[self.counter]
        print(f"ğŸ“ æ­£åœ¨å¤„ç†ç¬¬ {self.counter + 1}/{len(self.questions)} ä¸ªé—®é¢˜: {question}")
        self.counter += 1
        return question


class SafePrivateRetriever(MapFunction):
    """å¸¦è¶…æ—¶ä¿æŠ¤çš„ç§å¯†ä¿¡æ¯çŸ¥è¯†æ£€ç´¢å™¨"""
    def __init__(self, config, **kwargs):
        super().__init__(**kwargs)
        self.config = config
        self.collection_name = config.get("collection_name", "private_info_knowledge")
        self.index_name = config.get("index_name", "private_index")
        self.topk = config.get("ltm", {}).get("topk", 3)
        self.memory_service = None
        self.fallback_knowledge = [
            "å¼ å…ˆç”Ÿé€šå¸¸å°†æ‰‹æœºæ”¾åœ¨åŠå…¬æ¡Œå³ä¾§çš„æŠ½å±‰é‡Œï¼Œå……ç”µçº¿åœ¨å·¦ä¾§æŠ½å±‰ã€‚",
            "å¼ å…ˆç”Ÿçš„è½¦é’¥åŒ™ä¸€èˆ¬æ”¾åœ¨ç„å…³æŸœçš„å°ç›’å­é‡Œï¼Œå¤‡ç”¨é’¥åŒ™åœ¨å§å®¤æ¢³å¦†å°ã€‚",
            "å¼ å…ˆç”Ÿå–œæ¬¢åœ¨å‘¨äºŒå’Œå‘¨å››çš„ä¸‹åˆ3ç‚¹å»é™„è¿‘çš„å’–å•¡å…å·¥ä½œã€‚",
            "æå¥³å£«å–œæ¬¢æŠŠé’±åŒ…æ”¾åœ¨æ‰‹æåŒ…çš„å†…ä¾§æ‹‰é“¾è¢‹ä¸­ï¼Œä»ä¸æ”¾åœ¨å¤–å±‚ã€‚",
            "æå¥³å£«çš„æŠ¤ç…§å’Œé‡è¦è¯ä»¶æ”¾åœ¨å§å®¤è¡£æŸœé¡¶å±‚çš„è“è‰²æ–‡ä»¶å¤¹é‡Œã€‚",
            "æå¥³å£«çš„æ‰‹æœºé€šå¸¸æ”¾åœ¨å§å®¤åºŠå¤´æŸœä¸Šï¼Œä½†é’¥åŒ™æ”¾åœ¨å¨æˆ¿æŠ½å±‰é‡Œã€‚",
            "ç‹ç»ç†çš„åŠå…¬å®¤é’¥åŒ™é€šå¸¸æŒ‚åœ¨è…°é—´çš„é’¥åŒ™æ‰£ä¸Šï¼Œå¤‡ç”¨é’¥åŒ™åœ¨ç§˜ä¹¦é‚£é‡Œã€‚",
            "ç‹ç»ç†å¼€ä¼šæ—¶ä¹ æƒ¯å¸¦ç€é»‘è‰²çš„çš®è´¨è®°äº‹æœ¬ï¼Œé‡Œé¢è®°å½•ç€é‡è¦è”ç³»äººä¿¡æ¯ã€‚",
            "ç‹ç»ç†çš„æ‰‹æœºæ”¾åœ¨åŠå…¬æ¡Œä¸Šï¼Œä½†é‡è¦æ–‡ä»¶é”åœ¨ä¿é™©æŸœé‡Œã€‚",
            "å¼ å…ˆç”Ÿçš„é’±åŒ…æ”¾åœ¨è£¤å­å£è¢‹é‡Œï¼Œæå¥³å£«çš„è¯ä»¶åœ¨æŠ½å±‰ä¸­ã€‚"
        ]
        self._init_memory_service()

    def _init_memory_service(self):
        """å®‰å…¨åœ°åˆå§‹åŒ–memory service"""
        def init_service():
            try:
                from sage.service.memory.memory_service import MemoryService
                from sage.utils.embedding_methods.embedding_api import apply_embedding_model
                
                embedding_model = apply_embedding_model("default")
                memory_service = MemoryService()
                
                # æ£€æŸ¥é›†åˆæ˜¯å¦å­˜åœ¨
                collections = memory_service.list_collections()
                if collections["status"] == "success":
                    collection_names = [c["name"] for c in collections["collections"]]
                    if self.collection_name in collection_names:
                        return memory_service
                return None
            except Exception as e:
                print(f"åˆå§‹åŒ–memory serviceå¤±è´¥: {e}")
                return None

        try:
            with ThreadPoolExecutor() as executor:
                future = executor.submit(init_service)
                self.memory_service = future.result(timeout=5)  # 5ç§’è¶…æ—¶
                if self.memory_service:
                    print("Memory serviceåˆå§‹åŒ–æˆåŠŸ")
                else:
                    print("âš ï¸  Memory serviceåˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨å†…å­˜æ£€ç´¢")
        except TimeoutError:
            print("âš ï¸  Memory serviceåˆå§‹åŒ–è¶…æ—¶ï¼Œå°†ä½¿ç”¨å†…å­˜æ£€ç´¢")
            self.memory_service = None
        except Exception as e:
            print(f"âš ï¸  Memory serviceåˆå§‹åŒ–å¼‚å¸¸: {e}ï¼Œå°†ä½¿ç”¨å†…å­˜æ£€ç´¢")
            self.memory_service = None

    def _simple_text_search(self, query, topk=3):
        """ç®€å•çš„æ–‡æœ¬åŒ¹é…æ£€ç´¢"""
        keywords = []
        for keyword in ["å¼ å…ˆç”Ÿ", "æå¥³å£«", "ç‹ç»ç†", "æ‰‹æœº", "é’±åŒ…", "é’¥åŒ™", "å’–å•¡å…", "è¯ä»¶", "è®°äº‹æœ¬"]:
            if keyword in query:
                keywords.append(keyword)
        
        scored_sentences = []
        for sentence in self.fallback_knowledge:
            score = sum(1 for keyword in keywords if keyword in sentence)
            if score > 0:
                scored_sentences.append((sentence, score))
        
        scored_sentences.sort(key=lambda x: x[1], reverse=True)
        return [item[0] for item in scored_sentences[:topk]]

    def execute(self, data):
        if not data:
            return None

        query = data

        if self.memory_service:
            try:
                with ThreadPoolExecutor() as executor:
                    future = executor.submit(self._retrieve_real, query)
                    result = future.result(timeout=3)
                    return result
            except (TimeoutError, Exception):
                print(f"ğŸ” æ£€ç´¢å¼‚å¸¸ï¼Œä½¿ç”¨å†…å­˜æ£€ç´¢: {query}")
                retrieved_texts = self._simple_text_search(query, self.topk)
                print(f"   æ‰¾åˆ° {len(retrieved_texts)} æ¡ç›¸å…³ä¿¡æ¯")
                return (query, retrieved_texts)
        else:
            print(f"ğŸ” ä½¿ç”¨å†…å­˜æ£€ç´¢: {query}")
            retrieved_texts = self._simple_text_search(query, self.topk)
            print(f"   æ‰¾åˆ° {len(retrieved_texts)} æ¡ç›¸å…³ä¿¡æ¯")
            return (query, retrieved_texts)

    def _retrieve_real(self, query):
        """çœŸå®æ£€ç´¢"""
        result = self.memory_service.retrieve_data(
            collection_name=self.collection_name,
            query_text=query,
            topk=self.topk,
            index_name=self.index_name,
            with_metadata=True
        )

        if result['status'] == 'success':
            retrieved_texts = [item.get('text', '') for item in result['results']]
            return (query, retrieved_texts)
        else:
            return (query, [])


def pipeline_run(config: dict) -> None:
    """åˆ›å»ºå¹¶è¿è¡Œæ•°æ®å¤„ç†ç®¡é“"""
    retriever_config = config.get("retriever", {})
    collection_name = retriever_config.get("collection_name", "private_info_knowledge")
    index_name = retriever_config.get("index_name", "private_index")
    
    kb_builder = PrivateKnowledgeBuilder(collection_name, index_name)
    if not kb_builder.ensure_knowledge_base_exists():
        print("âŒ çŸ¥è¯†åº“å»ºç«‹å¤±è´¥ï¼Œç»ˆæ­¢ç¨‹åº")
        return
    
    print("âœ… çŸ¥è¯†åº“å‡†å¤‡å®Œæˆï¼Œå¼€å§‹æ„å»ºå¤„ç†ç®¡é“...")
    
    env = LocalEnvironment()

    (env
        .from_batch(PrivateQABatch, config["source"])
        .map(SafePrivateRetriever, config["retriever"])
        .map(QAPromptor, config["promptor"])
        .map(OpenAIGenerator, config["generator"]["remote"])
        .sink(TerminalSink, config["sink"])
    )

    try:
        print("ğŸš€ å¼€å§‹QAå¤„ç†...")
        print(f"ğŸ“Š å¤„ç†æµç¨‹: é—®é¢˜æº â†’ çŸ¥è¯†æ£€ç´¢ â†’ Promptæ„å»º â†’ AIç”Ÿæˆ â†’ ç»“æœè¾“å‡º")
        print("=" * 60)
        env.submit()
        time.sleep(10)
    except KeyboardInterrupt:
        print("âš ï¸  æµ‹è¯•ä¸­æ–­")
    finally:
        print("=" * 60)
        print("ğŸ æµ‹è¯•ç»“æŸ")
        env.close()


if __name__ == '__main__':
    CustomLogger.disable_global_console_debug()
    load_dotenv(override=False)
    config = load_config("config_batch.yaml")
    pipeline_run(config)