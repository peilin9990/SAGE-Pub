# ç¯å¢ƒç®¡ç† (Environments)

ç¯å¢ƒ (Environment) æ˜¯ SAGE Kernel çš„æ ¸å¿ƒæ¦‚å¿µï¼Œå®ƒå®šä¹‰äº†æ•°æ®æµåº”ç”¨çš„æ‰§è¡Œä¸Šä¸‹æ–‡ã€‚ç¯å¢ƒè´Ÿè´£ç®¡ç†è®¡ç®—èµ„æºã€è°ƒåº¦ä»»åŠ¡ã€å¤„ç†æœåŠ¡æ³¨å†Œç­‰ã€‚

## ğŸŒ ç¯å¢ƒç±»å‹

### 1. LocalEnvironment (æœ¬åœ°ç¯å¢ƒ)

é€‚ç”¨äºå•æœºå¼€å‘ã€æµ‹è¯•å’Œå°è§„æ¨¡æ•°æ®å¤„ç†ã€‚

```python
from sage.core.api.local_environment import LocalEnvironment

# åˆ›å»ºæœ¬åœ°ç¯å¢ƒ
env = LocalEnvironment("my_local_app")

# é…ç½®é€‰é¡¹
env = LocalEnvironment(
    name="my_app",
    config={
        "parallelism": 4,          # å¹¶è¡Œåº¦
        "buffer_size": 10000,      # ç¼“å†²åŒºå¤§å°
        "checkpoint_interval": 30  # æ£€æŸ¥ç‚¹é—´éš”(ç§’)
    }
)
```

### 2. RemoteEnvironment (è¿œç¨‹ç¯å¢ƒ)

é€‚ç”¨äºç”Ÿäº§ç¯å¢ƒå’Œåˆ†å¸ƒå¼é›†ç¾¤éƒ¨ç½²ã€‚

```python
from sage.core.api.remote_environment import RemoteEnvironment

# åˆ›å»ºè¿œç¨‹ç¯å¢ƒ
env = RemoteEnvironment(
    name="my_cluster_app",
    config={
        "jobmanager_host": "cluster-master",
        "jobmanager_port": 8081,
        "taskmanager_slots": 8
    }
)
```

## ğŸ”§ ç¯å¢ƒé…ç½®

### åŸºç¡€é…ç½®

```python
config = {
    # æ‰§è¡Œé…ç½®
    "parallelism": 4,              # é»˜è®¤å¹¶è¡Œåº¦
    "max_parallelism": 128,        # æœ€å¤§å¹¶è¡Œåº¦
    "buffer_size": 10000,          # æ•°æ®ç¼“å†²åŒºå¤§å°
    
    # å®¹é”™é…ç½®
    "restart_strategy": "fixed-delay",
    "restart_attempts": 3,
    "restart_delay": "10s",
    
    # æ£€æŸ¥ç‚¹é…ç½®
    "checkpointing_enabled": True,
    "checkpoint_interval": "30s",
    "checkpoint_timeout": "10m",
    
    # æ—¥å¿—é…ç½®
    "log_level": "INFO",
    "log_file": "./logs/sage.log"
}

env = LocalEnvironment("my_app", config=config)
```

### é«˜çº§é…ç½®

```python
# æ€§èƒ½è°ƒä¼˜é…ç½®
performance_config = {
    "network_buffer_size": "64mb",
    "sort_buffer_size": "64mb", 
    "hash_table_size": "1gb",
    "managed_memory_fraction": 0.7,
    "network_memory_fraction": 0.1,
    "jvm_heap_size": "2g"
}

# å®‰å…¨é…ç½®  
security_config = {
    "security_enabled": True,
    "kerberos_principal": "sage@REALM.COM",
    "ssl_enabled": True,
    "ssl_keystore": "./ssl/keystore.jks"
}
```

## ğŸ“Š æ•°æ®æºåˆ›å»º

### æ‰¹å¤„ç†æ•°æ®æº

```python
# ä»é›†åˆåˆ›å»º
stream = env.from_batch([1, 2, 3, 4, 5])

# ä»æ–‡ä»¶åˆ›å»º
stream = env.from_text_file("./data/input.txt")

# ä»å¤šä¸ªæ–‡ä»¶åˆ›å»º
stream = env.from_text_files("./data/*.txt")
```

### æµæ•°æ®æº

```python
# Kafkaæ•°æ®æº
stream = env.from_kafka_source(
    bootstrap_servers="localhost:9092",
    topic="my_topic",
    group_id="my_consumer_group",
    auto_offset_reset="latest"
)

# Socketæ•°æ®æº
stream = env.from_socket_text_stream("localhost", 9999)

# è‡ªå®šä¹‰æ•°æ®æº
class MySource(SourceFunction[str]):
    def run(self, ctx):
        for i in range(100):
            ctx.emit(f"Message {i}")
            time.sleep(1)

stream = env.add_source(MySource())
```

## ğŸ› ï¸ æœåŠ¡ç®¡ç†

### æœåŠ¡æ³¨å†Œ

```python
# æ³¨å†ŒæœåŠ¡ç±»
env.register_service("cache", RedisCacheService, 
                    host="localhost", port=6379)

# æ³¨å†ŒæœåŠ¡å·¥å‚
from sage.middleware import create_kv_service_factory

kv_factory = create_kv_service_factory("my_kv", backend_type="memory")
env.register_service_factory("my_kv", kv_factory)
```

### æœåŠ¡ä½¿ç”¨

```python
# åœ¨å¤„ç†å‡½æ•°ä¸­ä½¿ç”¨æœåŠ¡
class ProcessFunction(MapFunction[str, str]):
    def map(self, value: str) -> str:
        # è·å–æœåŠ¡ä»£ç†
        cache = self.get_runtime_context().get_service("cache")
        
        # ä½¿ç”¨æœåŠ¡
        result = cache.get(value)
        if result is None:
            result = expensive_computation(value)
            cache.put(value, result)
        
        return result

stream.map(ProcessFunction())
```

## ğŸš€ ä»»åŠ¡æäº¤å’Œç®¡ç†

### æäº¤ä»»åŠ¡

```python
# åŒæ­¥æäº¤ (é˜»å¡)
env.submit()

# å¼‚æ­¥æäº¤ (éé˜»å¡)
job_id = env.submit_async()

# å¸¦å‚æ•°æäº¤
env.submit(
    job_name="my_processing_job",
    save_point_path="./savepoints/sp_001",
    allow_non_restored_state=False
)
```

### ä»»åŠ¡æ§åˆ¶

```python
# åœæ­¢ä»»åŠ¡
env.stop()

# å–æ¶ˆä»»åŠ¡
env.cancel()

# æš‚åœä»»åŠ¡
env.pause()

# æ¢å¤ä»»åŠ¡
env.resume()

# åˆ›å»ºä¿å­˜ç‚¹
savepoint_path = env.create_savepoint()

# ä»ä¿å­˜ç‚¹æ¢å¤
env.restore_from_savepoint("./savepoints/sp_001")
```

## ğŸ“Š ç›‘æ§å’Œè°ƒè¯•

### æ€§èƒ½ç›‘æ§

```python
# å¯ç”¨æŒ‡æ ‡æ”¶é›†
env.enable_metrics(
    reporters=["jmx", "prometheus"],
    interval="10s"
)

# è‡ªå®šä¹‰æŒ‡æ ‡
counter = env.get_metric_group().counter("my_counter")
histogram = env.get_metric_group().histogram("my_histogram")

class MyMapFunction(MapFunction[str, str]):
    def map(self, value: str) -> str:
        counter.inc()  # å¢åŠ è®¡æ•°å™¨
        
        start_time = time.time()
        result = process(value)
        histogram.update(time.time() - start_time)  # è®°å½•å¤„ç†æ—¶é—´
        
        return result
```

### æ—¥å¿—é…ç½®

```python
# é…ç½®æ—¥å¿—
env.set_log_level("DEBUG")
env.set_log_file("./logs/my_app.log")

# ç»“æ„åŒ–æ—¥å¿—
logger = env.get_logger("MyFunction")
logger.info("Processing record", extra={"record_id": 123})
```

## ğŸ”§ æœ€ä½³å®è·µ

### 1. ç¯å¢ƒç”Ÿå‘½å‘¨æœŸç®¡ç†

```python
def main():
    env = None
    try:
        env = LocalEnvironment("my_app")
        
        # æ„å»ºæ•°æ®æµç®¡é“
        stream = env.from_batch(data)
        stream.map(process).sink(output)
        
        # æäº¤æ‰§è¡Œ
        env.submit()
        
    except Exception as e:
        logger.error(f"Job failed: {e}")
    finally:
        if env:
            env.close()  # ç¡®ä¿èµ„æºæ¸…ç†
```

### 2. é…ç½®å¤–éƒ¨åŒ–

```python
# config.yaml
parallelism: 4
buffer_size: 10000
checkpoint_interval: 30s

# Pythonä»£ç 
import yaml

with open("config.yaml") as f:
    config = yaml.safe_load(f)

env = LocalEnvironment("my_app", config=config)
```

### 3. é”™è¯¯å¤„ç†

```python
# è®¾ç½®é‡å¯ç­–ç•¥
env.set_restart_strategy(
    strategy="exponential-delay",
    max_attempts=5,
    initial_delay="1s",
    max_delay="1m",
    backoff_multiplier=2.0
)

# è‡ªå®šä¹‰é”™è¯¯å¤„ç†
class ErrorHandler(ProcessFunction[str, str]):
    def process(self, value: str, ctx: ProcessContext) -> str:
        try:
            return risky_operation(value)
        except Exception as e:
            # å‘é€åˆ°é”™è¯¯æµ
            ctx.output_to_side("errors", f"Error: {e}, Value: {value}")
            return None  # è¿‡æ»¤æ‰é”™è¯¯æ•°æ®

main_stream, error_stream = stream.process(ErrorHandler()).split()
```

### 4. èµ„æºä¼˜åŒ–

```python
# åˆç†è®¾ç½®å¹¶è¡Œåº¦
env.set_parallelism(min(cpu_count(), len(input_partitions)))

# å¯ç”¨å¯¹è±¡é‡ç”¨
env.enable_object_reuse()

# é…ç½®å†…å­˜ç®¡ç†
env.set_managed_memory_fraction(0.7)
env.set_network_memory_fraction(0.1)
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [æ•°æ®æµå¤„ç†](datastreams.md) - æ•°æ®æµæ“ä½œè¯¦è§£
- [å‡½æ•°æ¥å£](functions.md) - ç”¨æˆ·è‡ªå®šä¹‰å‡½æ•°
- [åˆ†å¸ƒå¼éƒ¨ç½²](../guides/distributed-deployment.md) - é›†ç¾¤éƒ¨ç½²æŒ‡å—
- [æ€§èƒ½ä¼˜åŒ–](../guides/performance.md) - æ€§èƒ½è°ƒä¼˜æŠ€å·§
