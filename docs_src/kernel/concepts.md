# SAGE Kernel æ ¸å¿ƒæ¦‚å¿µ

ç†è§£ SAGE Kernel çš„æ ¸å¿ƒæ¦‚å¿µæ˜¯é«˜æ•ˆä½¿ç”¨æ¡†æ¶çš„åŸºç¡€ã€‚æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»æ¡†æ¶ä¸­çš„å…³é”®æ¦‚å¿µå’Œæœ¯è¯­ã€‚

## ğŸŒŠ æ•°æ®æµ (DataStream)

### å®šä¹‰
DataStream æ˜¯ SAGE Kernel ä¸­çš„æ ¸å¿ƒæŠ½è±¡ï¼Œä»£è¡¨ä¸€ä¸ª**æœ‰ç•Œ**æˆ–**æ— ç•Œ**çš„æ•°æ®åºåˆ—ï¼Œæ˜¯æµå¤„ç†åº”ç”¨çš„åŸºç¡€æ„å»ºå—ã€‚

### ç‰¹æ€§
- **ä¸å¯å˜æ€§**: æ¯æ¬¡è½¬æ¢æ“ä½œéƒ½ä¼šåˆ›å»ºæ–°çš„æ•°æ®æµå®ä¾‹
- **å»¶è¿Ÿæ‰§è¡Œ**: æ„å»ºé˜¶æ®µåªåˆ›å»ºé€»è¾‘è®¡ç®—å›¾ï¼Œè°ƒç”¨ `execute()` æˆ– `submit()` æ—¶æ‰è§¦å‘å®é™…æ‰§è¡Œ
- **ç±»å‹å®‰å…¨**: åŸºäºæ³›å‹çš„ç¼–è¯‘æ—¶ç±»å‹æ£€æŸ¥ï¼Œå‡å°‘è¿è¡Œæ—¶é”™è¯¯
- **é“¾å¼è°ƒç”¨**: æ”¯æŒå‡½æ•°å¼ç¼–ç¨‹é£æ ¼ï¼Œä»£ç ç®€æ´æ˜“è¯»

### ç¤ºä¾‹ä»£ç 
```python
# åˆ›å»ºæœ‰ç•Œæ•°æ®æµï¼ˆæ‰¹å¤„ç†åœºæ™¯ï¼‰
batch_stream = env.from_collection([1, 2, 3, 4, 5])

# åˆ›å»ºæ— ç•Œæ•°æ®æµï¼ˆæµå¤„ç†åœºæ™¯ï¼‰
kafka_stream = env.from_kafka_source(
    bootstrap_servers="localhost:9092",
    topics=["input-topic"],
    group_id="consumer-group-1"
)

# å…¸å‹çš„é“¾å¼è½¬æ¢æ“ä½œ
processing_pipeline = (kafka_stream
    .map(lambda x: json.loads(x))      # è§£æJSON
    .filter(lambda x: x["is_valid"])   # è¿‡æ»¤æ— æ•ˆæ•°æ®
    .key_by(lambda x: x["user_id"])    # æŒ‰é”®åˆ†åŒº
    .window(TumblingWindow.of(Time.minutes(5)))  # 5åˆ†é’Ÿæ»šåŠ¨çª—å£
    .reduce(lambda a, b: a + b))       # èšåˆæ“ä½œ
```

## ğŸ—ï¸ ç¯å¢ƒ (Environment)

### å®šä¹‰
Environment å®šä¹‰äº†æ•°æ®æµåº”ç”¨çš„æ‰§è¡Œä¸Šä¸‹æ–‡ï¼Œè´Ÿè´£ç®¡ç†è®¡ç®—èµ„æºã€è°ƒåº¦ç­–ç•¥å’Œç³»ç»Ÿé…ç½®ã€‚

### ç¯å¢ƒç±»å‹å¯¹æ¯”

| ç‰¹æ€§ | LocalEnvironment | RemoteEnvironment |
|------|------------------|-------------------|
| **éƒ¨ç½²æ¨¡å¼** | å•æœºæœ¬åœ°æ‰§è¡Œ | åˆ†å¸ƒå¼é›†ç¾¤æ‰§è¡Œ |
| **é€‚ç”¨åœºæ™¯** | å¼€å‘æµ‹è¯•ã€å°è§„æ¨¡æ•°æ®å¤„ç† | ç”Ÿäº§ç¯å¢ƒã€å¤§è§„æ¨¡æµå¤„ç† |
| **èµ„æºç®¡ç†** | æœ¬åœ°èµ„æºé™åˆ¶ | é›†ç¾¤èµ„æºæ± åŒ–ç®¡ç† |
| **å®¹é”™èƒ½åŠ›** | æœ‰é™ | å®Œæ•´çš„æ•…éšœæ¢å¤æœºåˆ¶ |
| **çŠ¶æ€ç®¡ç†** | å†…å­˜çŠ¶æ€ | åˆ†å¸ƒå¼æŒä¹…åŒ–çŠ¶æ€ |

### é…ç½®ç¤ºä¾‹
```python
# æœ¬åœ°ç¯å¢ƒé…ç½® - é€‚åˆå¼€å‘æµ‹è¯•
local_env = LocalEnvironment(
    name="dev-environment",
    config={
        "parallelism": 4,           # å¹¶è¡Œåº¦
        "buffer.timeout": 100,      # ç¼“å†²åŒºè¶…æ—¶(ms)
        "state.backend": "memory",  # çŠ¶æ€åç«¯
        "checkpointing": False      # æ£€æŸ¥ç‚¹å¼€å…³
    }
)

# ç”Ÿäº§ç¯å¢ƒé…ç½® - åˆ†å¸ƒå¼é›†ç¾¤
prod_env = RemoteEnvironment(
    name="production-pipeline",
    config={
        "jobmanager.host": "cluster-master",
        "jobmanager.port": 8081,
        "taskmanager.slots": 32,
        "parallelism": 24,
        "state.backend": "rocksdb",
        "checkpoint.interval": "30s",
        "restart.strategy": "exponential-delay"
    }
)
```

## ğŸ”„ è½¬æ¢æ“ä½œ (Transformation)

### æ ¸å¿ƒè½¬æ¢æ“ä½œ

#### 1. åŸºæœ¬è½¬æ¢
```mermaid
flowchart LR
    A[åŸå§‹æ•°æ®æµ] --> B[Mapè½¬æ¢]
    B --> C[Filterè½¬æ¢]
    C --> D[FlatMapè½¬æ¢]
    D --> E[è½¬æ¢åæ•°æ®æµ]
    
    subgraph Mapè½¬æ¢
        B1[å…ƒç´ ç±»å‹è½¬æ¢]
        B2[æ•°æ® enrichment]
    end
    
    subgraph Filterè½¬æ¢
        C1[æ¡ä»¶è¿‡æ»¤]
        C2[æ•°æ®æ¸…æ´—]
    end
    
    subgraph FlatMapè½¬æ¢
        D1[ä¸€å¯¹å¤šæ˜ å°„]
        D2[æ•°æ®æ‹†åˆ†]
    end
```

#### 2. èšåˆè½¬æ¢
```python
# æ»šåŠ¨çª—å£èšåˆ
windowed_stream = (data_stream
    .key_by(lambda x: x["category"])
    .window(TumblingWindow.of(Time.minutes(10)))
    .aggregate(AverageAggregator()))

# ä¼šè¯çª—å£åˆ†æ
session_stream = (user_events
    .key_by(lambda x: x["session_id"])
    .window(SessionWindow.with_gap(Time.minutes(30)))
    .reduce(lambda a, b: merge_sessions(a, b)))
```

## â° æ—¶é—´è¯­ä¹‰ä¸çª—å£æœºåˆ¶

### æ—¶é—´ç±»å‹å¯¹æ¯”

| æ—¶é—´ç±»å‹ | å‡†ç¡®æ€§ | æ€§èƒ½ | é€‚ç”¨åœºæ™¯ |
|----------|--------|------|----------|
| **äº‹ä»¶æ—¶é—´** | â­â­â­â­â­ | â­â­ | éœ€è¦ç²¾ç¡®æ—¶é—´é¡ºåºçš„åœºæ™¯ |
| **å¤„ç†æ—¶é—´** | â­â­ | â­â­â­â­â­ | ä½å»¶è¿Ÿè¦æ±‚åœºæ™¯ |
| **æ‘„å…¥æ—¶é—´** | â­â­â­ | â­â­â­â­ | å¹³è¡¡å‡†ç¡®æ€§å’Œæ€§èƒ½ |

### æ°´ä½çº¿æœºåˆ¶
```mermaid
flowchart LR
    A[äº‹ä»¶æ—¶é—´æˆ³] --> B[æ°´ä½çº¿ç”Ÿæˆå™¨]
    B --> C{æ°´ä½çº¿åˆ¤æ–­}
    C --> D[å‡†æ—¶äº‹ä»¶]
    C --> E[å»¶è¿Ÿäº‹ä»¶]
    D --> F[çª—å£è®¡ç®—]
    E --> G[æ—è·¯è¾“å‡º/ä¸¢å¼ƒ]
    
    subgraph çª—å£è§¦å‘é€»è¾‘
        H[æ°´ä½çº¿åˆ°è¾¾çª—å£ç»“æŸæ—¶é—´] --> I[è§¦å‘çª—å£è®¡ç®—]
        J[å…è®¸å»¶è¿Ÿæ—¶é—´] --> K[å»¶è¿Ÿè§¦å‘æœºåˆ¶]
    end
```

### é…ç½®ç¤ºä¾‹
```python
# äº‹ä»¶æ—¶é—´é…ç½®
env.set_stream_time_characteristic(TimeCharacteristic.EVENT_TIME)

# æ°´ä½çº¿ç­–ç•¥
watermark_strategy = WatermarkStrategy\
    .for_bounded_out_of_orderness(Duration.of_seconds(5))\
    .with_timestamp_assigner(LambdaTimestampAssigner(lambda event: event["timestamp"]))

stream = stream.assign_timestamps_and_watermarks(watermark_strategy)
```

## ğŸªŸ çª—å£ç±»å‹è¯¦è§£

### çª—å£é…ç½®çŸ©é˜µ

| çª—å£ç±»å‹ | å›ºå®šå¤§å° | å¯é‡å  | åŠ¨æ€è°ƒæ•´ | é€‚ç”¨åœºæ™¯ |
|----------|----------|--------|----------|----------|
| **æ»šåŠ¨çª—å£** | âœ… | âŒ | âŒ | å®šæœŸç»Ÿè®¡æŠ¥è¡¨ |
| **æ»‘åŠ¨çª—å£** | âœ… | âœ… | âŒ | ç§»åŠ¨å¹³å‡è®¡ç®— |
| **ä¼šè¯çª—å£** | âŒ | âŒ | âœ… | ç”¨æˆ·è¡Œä¸ºåˆ†æ |
| **å…¨å±€çª—å£** | âŒ | âŒ | âŒ | éœ€è¦è‡ªå®šä¹‰è§¦å‘ |

### ä»£ç ç¤ºä¾‹
```python
# å¤šç§çª—å£é…ç½®ç¤ºä¾‹
tumbling_window = TumblingWindow.of(Time.minutes(5))  # 5åˆ†é’Ÿæ»šåŠ¨çª—å£
sliding_window = SlidingWindow.of(Time.minutes(10), Time.minutes(2))  # 10åˆ†é’Ÿçª—å£ï¼Œæ¯2åˆ†é’Ÿæ»‘åŠ¨
session_window = SessionWindow.with_gap(Time.minutes(30))  # 30åˆ†é’Ÿä¸æ´»åŠ¨åˆ™å…³é—­ä¼šè¯

# çª—å£å‡½æ•°åº”ç”¨
result = (stream
    .key_by(lambda x: x["key"])
    .window(tumbling_window)
    .apply(MyWindowFunction(),  # çª—å£å‡½æ•°
           TypeInformation.of(ResultType))  # è¾“å‡ºç±»å‹ä¿¡æ¯
```

## ğŸ›¡ï¸ å®¹é”™ä¸çŠ¶æ€ç®¡ç†

### çŠ¶æ€ç±»å‹å¯¹æ¯”

| çŠ¶æ€ç±»å‹ | å­˜å‚¨æ–¹å¼ | è®¿é—®æ¨¡å¼ | é€‚ç”¨åœºæ™¯ |
|----------|----------|----------|----------|
| **ValueState** | å•å¯¹è±¡ | è¯»å†™ | è®¡æ•°å™¨ã€æ ‡å¿—ä½ |
| **ListState** | å¯¹è±¡åˆ—è¡¨ | è¿½åŠ /éå† | äº‹ä»¶ç¼“å†²åŒº |
| **MapState** | é”®å€¼å¯¹ | éšæœºè®¿é—® | ç¼“å­˜ã€ç´¢å¼• |
| **ReducingState** | èšåˆå€¼ | å¢é‡æ›´æ–° | æŒç»­èšåˆ |

### æ£€æŸ¥ç‚¹æœºåˆ¶
```mermaid
flowchart TD
    A[æ£€æŸ¥ç‚¹åè°ƒå™¨] --> B[è§¦å‘æ£€æŸ¥ç‚¹]
    B --> C[æ‰€æœ‰ç®—å­å¿«ç…§çŠ¶æ€]
    C --> D[çŠ¶æ€æŒä¹…åŒ–å­˜å‚¨]
    D --> E[æ£€æŸ¥ç‚¹å®Œæˆ]
    
    F[æ•…éšœå‘ç”Ÿ] --> G[ä»æœ€è¿‘æ£€æŸ¥ç‚¹æ¢å¤]
    G --> H[é‡ç½®æ•°æ®æºä½ç½®]
    H --> I[æ¢å¤ç®—å­çŠ¶æ€]
    I --> J[ç»§ç»­å¤„ç†]
```

### é…ç½®ç¤ºä¾‹
```python
# æ£€æŸ¥ç‚¹é…ç½®
env.enable_checkpointing(
    interval=Duration.of_seconds(30),  # æ£€æŸ¥ç‚¹é—´éš”
    mode=CheckpointingMode.EXACTLY_ONCE,  # ç²¾ç¡®ä¸€æ¬¡è¯­ä¹‰
    timeout=Duration.of_minutes(5),  # è¶…æ—¶æ—¶é—´
    min_pause_between_checkpoints=Duration.of_seconds(10)  # æœ€å°é—´éš”
)

# çŠ¶æ€åç«¯é…ç½®
env.set_state_backend(RocksDBStateBackend(
    checkpoint_directory="hdfs://checkpoints/",
    incremental_checkpoints=True
))
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–æŒ‡å—

### ä¼˜åŒ–ç­–ç•¥çŸ©é˜µ

| ä¼˜åŒ–æŠ€æœ¯ | é€‚ç”¨åœºæ™¯ | æ€§èƒ½å½±å“ | å¤æ‚åº¦ |
|----------|----------|----------|--------|
| **ç®—å­é“¾ä¼˜åŒ–** | é«˜åååœºæ™¯ | â­â­â­â­â­ | â­â­ |
| **å¹¶è¡Œåº¦è°ƒæ•´** | è®¡ç®—å¯†é›†å‹ | â­â­â­â­ | â­â­â­ |
| **çŠ¶æ€åç«¯é€‰æ‹©** | å¤§çŠ¶æ€åº”ç”¨ | â­â­â­ | â­â­â­â­ |
| **åºåˆ—åŒ–ä¼˜åŒ–** | æ‰€æœ‰åœºæ™¯ | â­â­â­ | â­â­â­â­ |
| **èµ„æºè°ƒä¼˜** | é›†ç¾¤ç¯å¢ƒ | â­â­â­â­ | â­â­â­â­â­ |

### æœ€ä½³å®è·µç¤ºä¾‹
```python
# æ€§èƒ½ä¼˜åŒ–é…ç½®ç¤ºä¾‹
optimized_env = StreamExecutionEnvironment.get_execution_environment()

# è®¾ç½®å¹¶è¡Œåº¦
optimized_env.set_parallelism(16)

# å¯ç”¨å¯¹è±¡é‡ç”¨æ¨¡å¼ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰
optimized_env.get_config().enable_object_reuse()

# é…ç½®ç¼“å†²åŒºè¶…æ—¶
optimized_env.get_config().set_buffer_timeout(50)

# é€‰æ‹©é«˜æ•ˆåºåˆ—åŒ–å™¨
optimized_env.get_config().register_type_with_kryo_serializer(
    MyCustomType, CustomKryoSerializer()
)
```

## ğŸ” è°ƒè¯•ä¸ç›‘æ§

### ç›‘æ§æŒ‡æ ‡

| æŒ‡æ ‡ç±»åˆ« | å…·ä½“æŒ‡æ ‡ | é‡è¦æ€§ |
|----------|----------|--------|
| **ååé‡** | è®°å½•æ•°/ç§’ã€å­—èŠ‚æ•°/ç§’ | â­â­â­â­â­ |
| **å»¶è¿Ÿ** | å¤„ç†å»¶è¿Ÿã€ç«¯åˆ°ç«¯å»¶è¿Ÿ | â­â­â­â­ |
| **èµ„æº** | CPUä½¿ç”¨ç‡ã€å†…å­˜ä½¿ç”¨ã€ç½‘ç»œIO | â­â­â­â­ |
| **çŠ¶æ€** | çŠ¶æ€å¤§å°ã€æ£€æŸ¥ç‚¹æ—¶é—´ | â­â­â­ |
| **é”™è¯¯** | å¼‚å¸¸è®¡æ•°ã€é‡è¯•æ¬¡æ•° | â­â­â­ |

### è°ƒè¯•æŠ€å·§
```python
# è°ƒè¯•é…ç½®
env.set_parallelism(1)  # å•çº¿ç¨‹æ‰§è¡Œä¾¿äºè°ƒè¯•
env.disable_operator_chaining()  # ç¦ç”¨ç®—å­é“¾
env.enable_checkpointing(10000)  # æ›´é¢‘ç¹çš„æ£€æŸ¥ç‚¹

# æ·»åŠ è°ƒè¯•è¾“å‡º
debug_stream = data_stream\
    .map(lambda x: logging.debug(f"Processing: {x}"))\
    .name("debug_operator")
```

## ğŸ“š æ€»ç»“ä¸æœ€ä½³å®è·µ

### æ ¸å¿ƒåŸåˆ™
1. **é€‰æ‹©åˆé€‚çš„è¯­ä¹‰**: æ ¹æ®ä¸šåŠ¡éœ€æ±‚é€‰æ‹©ç²¾ç¡®ä¸€æ¬¡ã€è‡³å°‘ä¸€æ¬¡æˆ–è‡³å¤šä¸€æ¬¡è¯­ä¹‰
2. **åˆç†è®¾è®¡çª—å£**: æ ¹æ®æ•°æ®ç‰¹æ€§é€‰æ‹©é€‚å½“çš„çª—å£ç±»å‹å’Œå¤§å°
3. **ä¼˜åŒ–çŠ¶æ€ç®¡ç†**: æ ¹æ®è®¿é—®æ¨¡å¼é€‰æ‹©åˆé€‚çš„çŠ¶æ€ç±»å‹å’Œåç«¯
4. **ç›‘æ§å’Œè°ƒæ•´**: æŒç»­ç›‘æ§æ€§èƒ½æŒ‡æ ‡å¹¶ç›¸åº”è°ƒæ•´é…ç½®

### æ¨èé…ç½®
```python
# ç”Ÿäº§ç¯å¢ƒæ¨èé…ç½®
production_config = {
    "execution_mode": "EXACTLY_ONCE",
    "state_backend": "rocksdb",
    "checkpoint_interval": "30s",
    "watermark_interval": "200ms",
    "parallelism": "available_cores * 2",
    "buffer_timeout": "100ms",
    "restart_strategy": "exponential_delay"
}
```

---

é€šè¿‡æ·±å…¥ç†è§£è¿™äº›æ ¸å¿ƒæ¦‚å¿µï¼Œæ‚¨å°†èƒ½å¤Ÿæ›´å¥½åœ°è®¾è®¡å’Œä¼˜åŒ–åŸºäº SAGE Kernel çš„æµå¤„ç†åº”ç”¨ï¼Œæ„å»ºé«˜æ€§èƒ½ã€å¯é çš„æ•°æ®å¤„ç†ç®¡é“ã€‚